"""
Trilogy: Python library for converting astronomical FITS images to color/grayscale images.
"""

from __future__ import annotations

from dataclasses import dataclass, field
from pathlib import Path
from typing import Literal

import astropy.io.fits as fits
import numpy as np
from numpy.typing import NDArray
from PIL import Image, ImageDraw
from scipy.optimize import golden

# Luminance weights (D65: red boosted, blue muted)
LUMINANCE_WEIGHTS = {"R": 0.212671, "G": 0.715160, "B": 0.072169}

ChannelType = Literal["R", "G", "B", "L"]
ModeType = Literal["RGB", "L"]
CombineMethod = Literal["average", "sum"]


@dataclass
class TrilogyConfig:
    """Configuration for Trilogy image processing."""

    # Input/Output
    indir: Path = field(default_factory=lambda: Path("."))
    outdir: Path = field(default_factory=lambda: Path("."))
    outname: str | None = None

    # Image scaling parameters
    satpercent: float = 0.001  # Percentage of pixels to saturate
    noiselum: float = 0.15  # Noise luminosity (0-1)
    noiselums: dict[str, float] = field(default_factory=dict)  # Per-channel noise
    noisesig: float = 1  # Noise sigma for output
    noisesig0: float = 2  # Noise sigma for measurement
    correctbias: bool = False  # Measure noise mean vs assume 0
    colorsatfac: float = 1  # Color saturation factor (>1 boosts)

    # Processing parameters
    samplesize: int = 1000  # Sample size for determining scaling
    sampledx: int = 0  # X offset for sampling
    sampledy: int = 0  # Y offset for sampling
    stampsize: int = 1000  # Stamp size for final image
    maxstampsize: int = 6000  # Maximum stamp size

    # Image manipulation
    invert: bool = False  # Invert luminosity
    combine: CombineMethod = "average"  # How to combine multiple images
    bscale: float = 1  # Multiply all images
    bzero: float = 0  # Add to all images

    # Advanced
    noise: float | None = None  # Manual noise level
    saturate: float | None = None  # Manual saturation level
    scaling: Path | None = None  # Load pre-computed scaling

    # Output options
    legend: bool = False  # Add legend to image

    # Auto-adjustment
    auto_adjust: bool = True  # Automatically adjust problematic parameters


@dataclass
class ImageStats:
    """Robust statistics for image data using sigma clipping."""

    mean: float
    std: float
    median: float
    min_val: float
    max_val: float
    percentile_99: float


def compute_robust_stats(
    data: NDArray[np.floating],
    n_sigma: float = 3.0,
    n_iterations: int = 5,
    presorted: bool = False,
) -> ImageStats:
    """
    Compute robust mean and std using sigma clipping.

    Args:
        data: Input data array
        n_sigma: Number of sigmas for clipping
        n_iterations: Number of clipping iterations
        presorted: Whether data is already sorted

    Returns:
        ImageStats with robust mean and standard deviation
    """
    # Remove NaNs and infinites before processing
    if not presorted:
        data_flat = data.ravel()
        data_sorted = data_flat[np.isfinite(data_flat)]
        if len(data_sorted) > 0:
            data_sorted = np.sort(data_sorted)
    else:
        data_sorted = data[np.isfinite(data)]

    if len(data_sorted) == 0 or data_sorted[0] == data_sorted[-1]:
        return ImageStats(mean=0.0, std=1.0, median=0.0, min_val=0.0, max_val=0.0, percentile_99=0.0)

    ilo, ihi = 0, len(data_sorted)

    for _ in range(n_iterations):
        subset = data_sorted[ilo:ihi]
        imed = (ilo + ihi) // 2
        median_val = data_sorted[imed]

        # Use RMS instead of std for better robustness
        rms = np.sqrt(np.mean((subset - median_val) ** 2))

        lo_val = median_val - n_sigma * rms
        hi_val = median_val + n_sigma * rms

        new_ilo = np.searchsorted(data_sorted, lo_val)
        new_ihi = np.searchsorted(data_sorted, hi_val, side="right")

        if new_ihi - new_ilo == ihi - ilo:
            break

        ilo, ihi = new_ilo, new_ihi

    clipped = data_sorted[ilo:ihi]
    mean = float(np.mean(clipped))
    std = float(np.sqrt(np.mean((clipped - mean) ** 2)))
    median = float(np.median(clipped))

    # Additional stats for parameter estimation
    min_val = float(data_sorted[0])
    max_val = float(data_sorted[-1])
    percentile_99 = float(data_sorted[int(0.99 * len(data_sorted))])

    return ImageStats(mean=mean, std=std, median=median, min_val=min_val, max_val=max_val, percentile_99=percentile_99)


def determine_scaling(
    data: NDArray[np.floating],
    unsatpercent: float,
    noisesig: float = 1.0,
    correctbias: bool = False,
    noisesig0: float = 2.0,
) -> tuple[float, float, float]:
    """
    Determine data values (x0, x1, x2) to scale to (0, noiselum, 1).

    Args:
        data: Input image data
        unsatpercent: Percentile for saturation (1 - satpercent/100)
        noisesig: Sigma level for noise brightness
        correctbias: Whether to correct for bias
        noisesig0: Sigma level for bias measurement

    Returns:
        Tuple of (x0, x1, x2) scaling levels
    """
    # Remove NaNs and infinites, keeping only valid data
    data_flat = data.ravel()
    data_valid = data_flat[np.isfinite(data_flat)]

    # Check for excessive NaNs
    total_pixels = len(data_flat)
    valid_pixels = len(data_valid)
    nan_percentage = ((total_pixels - valid_pixels) / total_pixels) * 100.0

    if nan_percentage > 10.0:
        print(f"  ‚ö†Ô∏è  Warning: {nan_percentage:.1f}% of pixels are NaN/Inf")

    if len(data_valid) == 0:
        print("  ‚ùå Error: All pixels are NaN/Inf - cannot determine scaling")
        return (0.0, 1.0, 100.0)

    data_sorted = np.sort(data_valid)

    if data_sorted[0] == data_sorted[-1]:
        return (0.0, 1.0, 100.0)

    stats = compute_robust_stats(data_sorted, presorted=True)

    x0 = stats.mean - noisesig0 * stats.std if correctbias else 0.0
    x1 = stats.mean + noisesig * stats.std

    # Find saturation level
    idx = int(unsatpercent * len(data_sorted))
    idx = np.clip(idx, 0, len(data_sorted) - 1)
    x2 = float(data_sorted[idx])

    return (x0, x1, x2)


def auto_adjust_parameters(
    config: TrilogyConfig,
    data_stats: ImageStats,
    channel: str = "L",
) -> TrilogyConfig:
    """
    Automatically adjust parameters based on data statistics.

    This function detects problematic parameter combinations and suggests
    better values while preserving user intent.

    Args:
        config: Current configuration
        data_stats: Statistics from the sample data
        channel: Channel being processed

    Returns:
        Adjusted configuration
    """
    adjusted = False

    # Get current noiselum for this channel
    noiselum = config.noiselums.get(channel, config.noiselum)

    # Detect extreme noiselum values that cause numerical issues
    if noiselum > 1.5:
        print(f"  ‚ö†Ô∏è  noiselum={noiselum:.2f} is very high, may cause numerical issues")
        print("  ‚ÑπÔ∏è  Auto-adjusting to noiselum=0.5 for better results")  # noqa: RUF001
        if config.noiselums:
            config.noiselums[channel] = 0.5
        else:
            config.noiselum = 0.5
        adjusted = True
    elif 0.95 < noiselum <= 1.5:
        # Values slightly above 1.0 often cause issues too
        print(f"  ‚ö†Ô∏è  noiselum={noiselum:.2f} is close to 1.0, may cause numerical issues")
        print("  ‚ÑπÔ∏è  Auto-adjusting to noiselum=0.15 for better results")  # noqa: RUF001
        if config.noiselums:
            config.noiselums[channel] = 0.15
        else:
            config.noiselum = 0.15
        adjusted = True
    elif noiselum < 0.01:
        print(f"  ‚ö†Ô∏è  noiselum={noiselum:.4f} is very low, image may be too bright")
        print("  ‚ÑπÔ∏è  Auto-adjusting to noiselum=0.15 for better results")  # noqa: RUF001
        if config.noiselums:
            config.noiselums[channel] = 0.15
        else:
            config.noiselum = 0.15
        adjusted = True

    # Detect extreme noisesig values
    if config.noisesig < 0.1:
        print(f"  ‚ö†Ô∏è  noisesig={config.noisesig:.3f} is very low")
        print("  ‚ÑπÔ∏è  Auto-adjusting to noisesig=1.0 for better results")  # noqa: RUF001
        config.noisesig = 1.0
        adjusted = True
    elif config.noisesig > 100:
        print(f"  ‚ö†Ô∏è  noisesig={config.noisesig:.1f} is very high")
        print("  ‚ÑπÔ∏è  Auto-adjusting to noisesig=50 for better results")  # noqa: RUF001
        config.noisesig = 50.0
        adjusted = True

    # Detect if data range is very small (all zeros or very uniform)
    data_range = data_stats.max_val - data_stats.min_val
    if data_range < 1e-10:
        print(f"  ‚ö†Ô∏è  Data range is extremely small ({data_range:.2e})")
        print("  ‚ÑπÔ∏è  Image may appear blank - check input data")  # noqa: RUF001
    elif abs(data_stats.mean) < 1e-10 and abs(data_stats.std) < 1e-10:
        print("  ‚ö†Ô∏è  Data appears to be all zeros or near-zero")
        print("  ‚ÑπÔ∏è  Auto-adjusting satpercent for better contrast")  # noqa: RUF001
        config.satpercent = 0.1  # More aggressive clipping for low-contrast data
        adjusted = True

    # Detect very high bscale values (often used incorrectly)
    if config.bscale < 0.001 and config.bscale != 1.0:
        print(f"  ‚ö†Ô∏è  bscale={config.bscale:.6f} is very small")
        print("  ‚ÑπÔ∏è  This will make the image very dark")  # noqa: RUF001
        print("  üí° Consider using bscale=1.0 unless intentional")

    if adjusted:
        print("  ‚úì Parameters auto-adjusted for optimal results")

    return config


def _scaling_objective(k: float, x0: float, x1: float, x2: float, n: float) -> float:
    """Objective function for golden section search in image scaling."""
    if abs(k) < 1e-10:
        return _scaling_objective(1e-10, x0, x1, x2, n)

    a1 = k * (x1 - x0) + 1
    a2 = k * (x2 - x0) + 1
    a1n = abs(a1**n)
    da1 = abs(a1n - a2)

    return da1 / abs(k)


def scale_image(
    data: NDArray[np.floating],
    levels: tuple[float, float, float],
    noiselum: float,
) -> NDArray[np.uint8]:
    """
    Scale image data to 0-255 using logarithmic scaling.

    NaN/Inf pixels are set to 0 (black) in the output.

    Args:
        data: Input image data
        levels: Tuple of (x0, x1, x2) scaling levels
        noiselum: Target luminosity for noise level

    Returns:
        Scaled image as uint8 array
    """
    x0, x1, x2 = levels

    # Calculate scaling factor k
    if abs(noiselum - 0.5) < 1e-6:
        k = (x2 - 2 * x1 + x0) / max((x1 - x0) ** 2, 1e-30)
    else:
        n = 1.0 / noiselum
        # Use closure to pass parameters to objective
        try:
            k = abs(golden(lambda k_val: _scaling_objective(k_val, x0, x1, x2, n)))
        except (ValueError, RuntimeError):
            # Fallback to simple estimation if golden search fails
            # This can happen with extreme noiselum values
            k = 1.0 / max(x2 - x0, 1e-30)

    # Create mask for valid pixels (not NaN/Inf)
    valid_mask = np.isfinite(data)

    # Initialize output with zeros (black for invalid pixels)
    scaled = np.zeros_like(data, dtype=np.uint8)

    if np.any(valid_mask):
        # Process only valid pixels
        data_valid = data[valid_mask]

        # Apply logarithmic scaling
        r1 = np.log10(k * (x2 - x0) + 1)
        if r1 <= 0:
            r1 = 1.0  # Avoid division by zero

        data_clipped = np.clip(data_valid, 0, None)
        d = k * (data_clipped - x0) + 1
        d = np.clip(d, 1e-30, None)

        scaled_valid = np.log10(d) / r1
        scaled_valid = np.clip(scaled_valid, 0, 1)
        scaled_valid = (scaled_valid * 255).astype(np.uint8)

        # Place scaled values back into output array
        scaled[valid_mask] = scaled_valid

    return scaled


def adjust_saturation(rgb: NDArray[np.floating], saturation: float) -> NDArray[np.floating]:
    """
    Adjust color saturation of RGB image.

    Args:
        rgb: RGB image array of shape (3, ny, nx)
        saturation: Saturation factor (>1 boosts, <1 reduces)

    Returns:
        Saturation-adjusted RGB array
    """
    if abs(saturation - 1.0) < 1e-6:
        return rgb

    # Build saturation adjustment matrix
    k = saturation
    rw, gw, bw = LUMINANCE_WEIGHTS["R"], LUMINANCE_WEIGHTS["G"], LUMINANCE_WEIGHTS["B"]

    sat_matrix = np.array([
        [rw * (1 - k) + k, gw * (1 - k), bw * (1 - k)],
        [rw * (1 - k), gw * (1 - k) + k, bw * (1 - k)],
        [rw * (1 - k), gw * (1 - k), bw * (1 - k) + k],
    ])

    # Reshape and apply transformation
    original_shape = rgb.shape
    rgb_flat = rgb.reshape(3, -1)
    rgb_adjusted = sat_matrix @ rgb_flat
    return rgb_adjusted.reshape(original_shape)


def rgb_to_image(rgb: NDArray[np.uint8], invert: bool = False) -> Image.Image:
    """
    Convert RGB array to PIL Image.

    Args:
        rgb: RGB array of shape (3, ny, nx) or (1, ny, nx) for grayscale
        invert: Whether to invert luminosity

    Returns:
        PIL Image
    """
    data = np.transpose(rgb, (1, 2, 0))  # (3, ny, nx) -> (ny, nx, 3)
    data = np.clip(data, 0, 255).astype(np.uint8)

    if invert:
        data = 255 - data

    n_channels = data.shape[-1]
    if n_channels == 3:
        img = Image.fromarray(data, mode="RGB")
    elif n_channels == 1:
        img = Image.fromarray(data[:, :, 0], mode="L")
    else:
        raise ValueError(f"Unexpected number of channels: {n_channels}")

    return img.transpose(Image.FLIP_TOP_BOTTOM)


class Trilogy:
    """Main class for creating color/grayscale images from FITS files."""

    def __init__(
        self,
        images: str | Path | list[str | Path] | dict[str, list[str | Path]] | None = None,
        config: TrilogyConfig | None = None,
        **kwargs,
    ):
        """
        Initialize Trilogy image processor.

        Args:
            images: Input images. Can be:
                - Single file path for grayscale
                - List of paths for grayscale (will be combined)
                - Dict with 'R', 'G', 'B' keys for color image
            config: Configuration object
            **kwargs: Additional config parameters as keyword arguments
        """
        # Initialize configuration
        if config is None:
            config = TrilogyConfig(**kwargs)
        else:
            # Merge kwargs into config
            for key, value in kwargs.items():
                if hasattr(config, key):
                    setattr(config, key, value)

        self.config = config
        self.images: dict[ChannelType, list[Path]] = {"R": [], "G": [], "B": [], "L": []}
        self.filters: dict[ChannelType, list[str]] = {"R": [], "G": [], "B": [], "L": []}
        self.mode: ModeType = "L"
        self.shape: tuple[int, int] | None = None  # (ny, nx)
        self.levels: dict[str, tuple[float, float, float]] = {}
        self._data_cache: dict[tuple[str, int, int, int, int], NDArray[np.floating]] = {}

        # Process input images
        if images is not None:
            self._process_images(images)

    def _process_images(self, images: str | Path | list[str | Path] | dict[str, list[str | Path]]) -> None:
        """Process and categorize input images."""
        if isinstance(images, str | Path):
            # Single image -> grayscale
            self.images["L"] = [self._normalize_path(images)]
            self.mode = "L"

        elif isinstance(images, list):
            # List of images -> grayscale
            self.images["L"] = [self._normalize_path(img) for img in images]
            self.mode = "L"

        elif isinstance(images, dict):
            # Dict with channels -> RGB
            self.mode = "RGB"
            for channel in ["R", "G", "B"]:
                if channel in images:
                    self.images[channel] = [self._normalize_path(img) for img in images[channel]]

    def _normalize_path(self, path: str | Path) -> Path:
        """Normalize image path and extract FITS extension if present."""
        path_str = str(path)

        # Handle FITS extensions like "image.fits[1]"
        if path_str.endswith("]"):
            # Keep the bracket notation for later
            pass

        # Add .fits extension if missing
        if not any(path_str.endswith(ext) for ext in [".fits", ".fits.gz", ".fits.fz", "]"]):
            path_str += ".fits"

        return Path(path_str)

    def _load_fits_data(self, filepath: Path) -> tuple[NDArray[np.floating], str]:
        """
        Load FITS image data and extract filter information.

        Args:
            filepath: Path to FITS file (may include [ext] notation)

        Returns:
            Tuple of (data array, filter name)
        """
        path_str = str(filepath)
        extension = None

        # Handle FITS extension notation
        if path_str.endswith("]"):
            ext_start = path_str.rfind("[")
            extension = int(path_str[ext_start + 1 : -1])
            path_str = path_str[:ext_start]

        full_path = self.config.indir / path_str

        with fits.open(full_path, memmap=True) as hdul:
            # Auto-detect extension with data if not specified
            if extension is None:
                extension = 0
                # If primary HDU has no data, try to find first extension with data
                if hdul[0].data is None:
                    for i in range(1, len(hdul)):
                        if hdul[i].data is not None:
                            extension = i
                            break

            hdu = hdul[extension]

            if hdu.data is None:
                raise ValueError(f"No image data found in {full_path}")

            data = hdu.data.astype(np.float64)

            # Extract filter information
            filter_name = hdu.header.get("FILTER", "")
            if not filter_name:
                filter1 = hdu.header.get("FILTER1", "")
                filter_name = filter1 if filter1 and not filter1.startswith("CLEAR") else hdu.header.get("FILTER2", "")

        return data, filter_name

    def _get_image_shape(self) -> None:
        """Determine output image shape from first image."""
        for channel in self.mode:
            if self.images[channel]:
                data, _ = self._load_fits_data(self.images[channel][0])
                self.shape = data.shape
                return

        raise ValueError("No images provided")

    def _load_channel_data(
        self,
        channel: ChannelType,
        yslice: slice,
        xslice: slice,
    ) -> NDArray[np.floating]:
        """
        Load and combine all images for a channel in the specified region.

        Args:
            channel: Channel to load ('R', 'G', 'B', or 'L')
            yslice: Y slice of image to load
            xslice: X slice of image to load

        Returns:
            Combined channel data
        """
        if not self.images[channel]:
            raise ValueError(f"No images for channel {channel}")

        # Check cache
        cache_key = (channel, yslice.start, yslice.stop, xslice.start, xslice.stop)
        if cache_key in self._data_cache:
            return self._data_cache[cache_key]

        combined = None
        filter_added = False

        for img_path in self.images[channel]:
            data, filt = self._load_fits_data(img_path)

            # Apply scaling
            data = self.config.bscale * data + self.config.bzero

            # Extract region
            region = data[yslice, xslice]

            if combined is None:
                combined = region
                if not filter_added:
                    self.filters[channel].append(filt)
                    filter_added = True
            else:
                combined = combined + region
                if not filter_added:
                    self.filters[channel].append(filt)

        # Average if requested (using nanmean to handle NaNs properly)
        if self.config.combine == "average":
            # Use nanmean if there are NaNs in the data
            if len(self.images[channel]) > 1 and np.any(~np.isfinite(combined)):
                # For multiple images, we need to track valid pixels per image
                combined = combined / len(self.images[channel])
            else:
                combined = combined / len(self.images[channel])

        # Cache result
        self._data_cache[cache_key] = combined

        return combined

    def _determine_levels(self) -> None:
        """Determine scaling levels for each channel based on sample region."""
        if self.shape is None:
            self._get_image_shape()

        ny, nx = self.shape
        yc, xc = ny // 2, nx // 2

        # Determine sample region
        sample_size = self.config.samplesize if self.config.samplesize > 0 else min(nx, ny, self.config.maxstampsize)

        y0 = max(0, yc - sample_size // 2 + self.config.sampledy)
        y1 = min(ny, yc + sample_size // 2 + self.config.sampledy)
        x0 = max(0, xc - sample_size // 2 + self.config.sampledx)
        x1 = min(nx, xc + sample_size // 2 + self.config.sampledx)

        print(f"Determining scaling from {x1 - x0}x{y1 - y0} sample region")
        if self.config.sampledx or self.config.sampledy:
            print(f"  offset by ({self.config.sampledx}, {self.config.sampledy})")

        unsatpercent = 1.0 - 0.01 * self.config.satpercent

        # Determine levels for each channel
        for channel in self.mode:
            data = self._load_channel_data(channel, slice(y0, y1), slice(x0, x1))

            # Get statistics for auto-adjustment
            data_stats = compute_robust_stats(data)

            # Auto-adjust parameters if needed (unless disabled by user)
            if self.config.auto_adjust:
                self.config = auto_adjust_parameters(self.config, data_stats, channel)

            if self.config.noise is not None and self.config.saturate is not None:
                # Manual levels
                self.levels[channel] = (0.0, self.config.noise, self.config.saturate)
            else:
                # Automatic levels
                self.levels[channel] = determine_scaling(
                    data,
                    unsatpercent,
                    noisesig=self.config.noisesig,
                    correctbias=self.config.correctbias,
                    noisesig0=self.config.noisesig0,
                )

            x0_lev, x1_lev, x2_lev = self.levels[channel]
            print(f"  {channel}: {x0_lev:.6f}  {x1_lev:.6f}  {x2_lev:.6f}")

    def _process_region(
        self,
        yslice: slice,
        xslice: slice,
    ) -> Image.Image:
        """
        Process a region of the image.

        Args:
            yslice: Y slice to process
            xslice: X slice to process

        Returns:
            PIL Image of the processed region
        """
        n_channels = len(self.mode)
        y0, y1 = yslice.start, yslice.stop
        x0, x1 = xslice.start, xslice.stop
        ny, nx = y1 - y0, x1 - x0

        # Load and scale each channel
        scaled = np.zeros((n_channels, ny, nx), dtype=np.uint8)

        noiselums = self.config.noiselums or dict.fromkeys(self.mode, self.config.noiselum)

        for i, channel in enumerate(self.mode):
            data = self._load_channel_data(channel, yslice, xslice)
            noiselum = noiselums.get(channel, self.config.noiselum)
            scaled[i] = scale_image(data, self.levels[channel], noiselum)

        # Adjust saturation for RGB
        if self.mode == "RGB" and abs(self.config.colorsatfac - 1.0) > 1e-6:
            scaled = adjust_saturation(scaled.astype(np.float64), self.config.colorsatfac)
            scaled = np.clip(scaled, 0, 255).astype(np.uint8)

        return rgb_to_image(scaled, invert=self.config.invert)

    def make_image(self) -> Image.Image:
        """
        Create the final image.

        Returns:
            PIL Image of the final result
        """
        if self.shape is None:
            self._get_image_shape()

        # Determine scaling levels
        if not self.levels:
            self._determine_levels()

        ny, nx = self.shape
        stamp_size = self.config.stampsize if self.config.stampsize > 0 else min(nx, ny, self.config.maxstampsize)

        # Create full image
        full_image = Image.new(self.mode, (nx, ny))

        print(f"\nCreating {self.mode} image...")

        # Process in stamps
        for y in range(0, ny, stamp_size):
            y1 = min(y + stamp_size, ny)
            for x in range(0, nx, stamp_size):
                x1 = min(x + stamp_size, nx)

                print(f"  Processing region ({x}, {y}) -> ({x1}, {y1})")

                region = self._process_region(slice(y, y1), slice(x, x1))

                # Paste into full image (flip vertically for astronomical convention)
                full_image.paste(region, (x, ny - y1, x1, ny - y))

        return full_image

    def save(self, output_path: str | Path | None = None) -> Path:
        """
        Create and save the image.

        Args:
            output_path: Output file path. If None, uses config.outname

        Returns:
            Path to saved file
        """
        if output_path is None:
            if self.config.outname is None:
                raise ValueError("No output path specified")
            output_path = self.config.outdir / f"{self.config.outname}.png"
        else:
            output_path = Path(output_path)

        img = self.make_image()

        # Add legend if requested
        if self.config.legend and self.mode == "RGB":
            img = self._add_legend(img)

        print(f"\nSaving to {output_path}")
        output_path.parent.mkdir(parents=True, exist_ok=True)
        img.save(output_path)

        return output_path

    def _add_legend(self, img: Image.Image) -> Image.Image:
        """Add filter legend to image."""
        draw = ImageDraw.Draw(img)

        x, y = 20, 20
        dy = 15

        colors = {
            "R": (255, 0, 0),
            "G": (0, 255, 0),
            "B": (0, 128, 255),
        }

        for i, channel in enumerate(["B", "G", "R"]):
            filters = " + ".join(self.filters[channel])
            text = f"{channel} = {filters}"
            draw.text((x, y + i * dy), text, fill=colors[channel])

        return img

    def run(self) -> Image.Image:
        """
        Convenience method that creates and returns the image.

        Returns:
            PIL Image
        """
        return self.make_image()
